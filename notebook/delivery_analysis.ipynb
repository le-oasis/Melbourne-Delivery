{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f9faae4-1e3e-48ba-a3cd-d6970db40272",
   "metadata": {
    "id": "2f9faae4-1e3e-48ba-a3cd-d6970db40272"
   },
   "source": [
    "## Step 0: Initiate Libraries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c231464-4a4b-4a66-8321-f96302dc09e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T14:45:29.892708Z",
     "start_time": "2023-07-04T14:45:29.731937Z"
    },
    "id": "0c231464-4a4b-4a66-8321-f96302dc09e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "\n",
    "# Import Key Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Import Data Preprocessing Libraries\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# ast : Abstract Syntax Trees\n",
    "from ast import literal_eval\n",
    "\n",
    "# Import Geospatial Libraries\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from geopy.distance import geodesic\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import *\n",
    "import reverse_geocoder as rg \n",
    "\n",
    "# Datetime\n",
    "import datetime\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "# Data Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "import plotly.graph_objs as go\n",
    "from plotly.tools import FigureFactory as FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4266a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc40e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34a3830a-cb7f-48ea-8e25-3c4aa759032e",
   "metadata": {
    "id": "34a3830a-cb7f-48ea-8e25-3c4aa759032e"
   },
   "source": [
    "## Step 1: Read Data\n",
    "\n",
    "- Here will we be reading the raw data as -  `dirty_data.csv` file into our jupyter notebook.\n",
    "- The variable name for the Food Delivery data would be called `dataset` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633453ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T14:45:29.903414Z",
     "start_time": "2023-07-04T14:45:29.893924Z"
    },
    "id": "633453ac",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the file path\n",
    "file_path = os.path.join(os.pardir, os.pardir, 'Melbourne-Delivery/data/dirty_data.csv')\n",
    "\n",
    "# Load the file into a DataFrame\n",
    "delivery_data = pd.read_csv(file_path)\n",
    "\n",
    "# Copy the data\n",
    "orders_df = delivery_data.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18a20a56-37c2-4dfb-8f66-28142e01931e",
   "metadata": {
    "id": "18a20a56-37c2-4dfb-8f66-28142e01931e"
   },
   "source": [
    "### Step 1.1: Data Discovery (Building Intuition)\n",
    "\n",
    "- This is a technique we use to get an initial feel for our data tables.\n",
    "- We read the data using pandas and perform method calls.\n",
    "- Standardize dataset columns in the correct format.\n",
    "- Explore Descriptive Statistics on Numerical Columns and more below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63e102aa",
   "metadata": {
    "id": "63e102aa"
   },
   "source": [
    "##### `df.info()`\n",
    "\n",
    "- It is an important and widely used method of Python.\n",
    "- This Method prints the information or summary of the dataframe.\n",
    "- It prints the various information of the Dataframe such as index type, dtype, columns, non-values, and memory usage. It gives a quick overview of the dataset.\n",
    "- Info Method to get the Non-Null Count & Dtype (data type) of the dataset,\n",
    "- Validate if a column and column type aligns with the format of the Business Requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c083d1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T14:45:29.955377Z",
     "start_time": "2023-07-04T14:45:29.922555Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c083d1a",
    "outputId": "2283d68b-902c-45d7-d0e1-f39f87c8390c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   order_id                 500 non-null    object \n",
      " 1   date                     500 non-null    object \n",
      " 2   time                     500 non-null    object \n",
      " 3   order_type               500 non-null    object \n",
      " 4   branch_code              500 non-null    object \n",
      " 5   order_items              500 non-null    object \n",
      " 6   order_price              500 non-null    float64\n",
      " 7   customer_lat             500 non-null    float64\n",
      " 8   customer_lon             500 non-null    float64\n",
      " 9   customerHasloyalty?      500 non-null    int64  \n",
      " 10  distance_to_customer_KM  500 non-null    float64\n",
      " 11  delivery_fee             500 non-null    float64\n",
      "dtypes: float64(5), int64(1), object(6)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "orders_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458dc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bFjYKlKRSj4-",
   "metadata": {
    "id": "bFjYKlKRSj4-"
   },
   "source": [
    "### Step 1.2: Data Preporcessing - Cleaning \n",
    "\n",
    "- Here we will be cleaning the data by converting the columns to the correct data types.\n",
    "- We will merge the date and time columns into one column called `order_date` and convert it to a datetime type.\n",
    "- We will also rename the `customerHasloyalty?` , `distance_to_customer_KM` columns to `customer_loyalty` , and  `distance_to_customer` respectively.\n",
    "- We will add an additional column called `updated at` which will be the date and time the data was updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eNo-KF7Sj1V",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T14:45:38.184964Z",
     "start_time": "2023-07-04T14:45:38.169814Z"
    },
    "id": "4eNo-KF7Sj1V",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   order_id                 500 non-null    int64         \n",
      " 1   order_date               500 non-null    datetime64[ns]\n",
      " 2   order_type               500 non-null    category      \n",
      " 3   branch_code              500 non-null    category      \n",
      " 4   order_items              500 non-null    object        \n",
      " 5   order_price              500 non-null    float64       \n",
      " 6   customer_loyalty         500 non-null    bool          \n",
      " 7   distance_to_customer_km  500 non-null    float64       \n",
      " 8   delivery_fee             500 non-null    float64       \n",
      " 9   location                 500 non-null    object        \n",
      " 10  updated_at               500 non-null    datetime64[ns]\n",
      "dtypes: bool(1), category(2), datetime64[ns](2), float64(3), int64(1), object(2)\n",
      "memory usage: 33.1+ KB\n"
     ]
    }
   ],
   "source": [
    "def reverseGeocode(coordinates): \n",
    "    result = rg.search(coordinates)\n",
    "    return (result)\n",
    "\n",
    "def cleaning_data_types(orders_df):\n",
    "    # Create a copy of the DataFrame to avoid modifying the original one\n",
    "    df_clean = orders_df.copy()\n",
    "\n",
    "    # Define helper function to clean date data\n",
    "    def clean_date(date_str):\n",
    "        date_str = date_str.strip()\n",
    "        date = parse(date_str, dayfirst=True)  # dayfirst=True to handle DD/MM/YYYY properly\n",
    "        return date.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Convert columns to appropriate data types\n",
    "    df_clean['order_id'] = df_clean['order_id'].str.extract('(\\d+)').astype(int)\n",
    "    df_clean['date'] = df_clean['date'].apply(clean_date).astype('datetime64[ns]')\n",
    "    df_clean['datetime'] = pd.to_datetime(df_clean['date'].astype(str) + ' ' + df_clean['time'])\n",
    "    df_clean[\"order_type\"] = df_clean[\"order_type\"].astype(\"category\")\n",
    "\n",
    "   \n",
    "    # Convert 'branch_code' to upper case to handle case-insensitive duplicates\n",
    "    df_clean[\"branch_code\"] = df_clean[\"branch_code\"].str.upper().astype(\"category\")\n",
    "\n",
    "\n",
    "    # Use exception handling for potential errors in the literal_eval() function\n",
    "    try:\n",
    "        df_clean[\"order_items\"] = df_clean[\"order_items\"].apply(literal_eval)\n",
    "    except (ValueError, SyntaxError):\n",
    "        pass\n",
    "\n",
    "    # Continue with the remaining conversions\n",
    "    df_clean[\"order_price\"] = df_clean[\"order_price\"].astype(float)\n",
    "    df_clean[\"customer_lat\"] = df_clean[\"customer_lat\"].astype(float)\n",
    "    df_clean[\"customer_lon\"] = df_clean[\"customer_lon\"].astype(float)\n",
    "    df_clean[\"customerHasloyalty?\"] = df_clean[\"customerHasloyalty?\"].astype(bool)\n",
    "    df_clean[\"distance_to_customer_KM\"] = df_clean[\"distance_to_customer_KM\"].astype(float)\n",
    "    df_clean[\"delivery_fee\"] = df_clean[\"delivery_fee\"].astype(float)\n",
    "\n",
    "\n",
    "    # make the order_price two decimal places\n",
    "    df_clean['order_price'] = df_clean['order_price'].round(2)\n",
    "\n",
    "    # make the delivery fee two decimal places\n",
    "    df_clean['delivery_fee'] = df_clean['delivery_fee'].round(2)\n",
    "\n",
    "\n",
    "    # transform long/lat into state\n",
    "    coordinates =list(zip(df_clean['customer_lat'],df_clean['customer_lon'])) # generates pair of (lat,long)\n",
    "    data = reverseGeocode(coordinates)\n",
    "\n",
    "\n",
    "    # Create a new column with the City name    \n",
    "    df_clean['name'] = [i['name'] for i in data]\n",
    "    df_clean['admin1'] = [i['admin1'] for i in data]\n",
    "    df_clean['admin2'] = [i['admin2'] for i in data]\n",
    "\n",
    "\n",
    "    df_clean.drop(['admin1', 'admin2'], axis=1, inplace=True)\n",
    "    df_clean.rename(columns={'name': 'location'}, inplace=True)\n",
    " \n",
    "\n",
    "    # Rename the customerHasloyalty? column to customerHasloyalty\n",
    "    df_clean.rename(columns={'customerHasloyalty?': 'customer_loyalty'}, inplace=True)\n",
    "\n",
    "    # Rename the distance_to_customer_KM column to distance_to_customer_km\n",
    "    df_clean.rename(columns={'distance_to_customer_KM': 'distance_to_customer_km'}, inplace=True)\n",
    "\n",
    "    # Drop the 'date' and 'time' columns\n",
    "    df_clean.drop(['date', 'time'], axis=1, inplace=True)\n",
    "\n",
    "    # Rename the 'datetime' column to 'order_date' and move it to the second position\n",
    "    df_clean.rename(columns={'datetime': 'order_date'}, inplace=True)\n",
    "    order_date = df_clean.pop('order_date')\n",
    "    df_clean.insert(1, 'order_date', order_date)\n",
    "\n",
    "    # Add the 'updated_at' column with the current datetime\n",
    "    df_clean['updated_at'] = datetime.datetime.today().replace(second=0, microsecond=0)\n",
    "\n",
    "    df_clean.drop(['customer_lat', 'customer_lon'], axis=1, inplace=True)\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "df_clean = cleaning_data_types(orders_df)\n",
    "df_clean.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f6f7de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>order_type</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>order_items</th>\n",
       "      <th>order_price</th>\n",
       "      <th>customer_loyalty</th>\n",
       "      <th>distance_to_customer_km</th>\n",
       "      <th>delivery_fee</th>\n",
       "      <th>location</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1406</td>\n",
       "      <td>2018-07-08 15:16:03</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Fries, 6), (Salad, 4)]</td>\n",
       "      <td>140.80</td>\n",
       "      <td>True</td>\n",
       "      <td>8.335</td>\n",
       "      <td>13.70</td>\n",
       "      <td>Docklands</td>\n",
       "      <td>2023-07-06 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10125</td>\n",
       "      <td>2018-12-01 08:20:16</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Cereal, 8), (Pancake, 6)]</td>\n",
       "      <td>313.50</td>\n",
       "      <td>True</td>\n",
       "      <td>7.536</td>\n",
       "      <td>6.17</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>2023-07-06 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4175</td>\n",
       "      <td>2018-06-07 14:05:04</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Steak, 3), (Salad, 1), (Chicken, 6), (Fries,...</td>\n",
       "      <td>714.00</td>\n",
       "      <td>False</td>\n",
       "      <td>9.860</td>\n",
       "      <td>15.09</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>2023-07-06 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3691</td>\n",
       "      <td>2018-04-26 11:43:05</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Pancake, 9), (Eggs, 10), (Cereal, 2)]</td>\n",
       "      <td>480.25</td>\n",
       "      <td>False</td>\n",
       "      <td>8.614</td>\n",
       "      <td>13.68</td>\n",
       "      <td>Southbank</td>\n",
       "      <td>2023-07-06 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4094</td>\n",
       "      <td>2018-04-10 11:12:40</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Eggs, 5), (Coffee, 3), (Pancake, 9), (Cereal...</td>\n",
       "      <td>497.75</td>\n",
       "      <td>False</td>\n",
       "      <td>8.802</td>\n",
       "      <td>13.76</td>\n",
       "      <td>Southbank</td>\n",
       "      <td>2023-07-06 02:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id          order_date order_type branch_code   \n",
       "0      1406 2018-07-08 15:16:03      Lunch          NS  \\\n",
       "1     10125 2018-12-01 08:20:16  Breakfast          NS   \n",
       "2      4175 2018-06-07 14:05:04      Lunch          NS   \n",
       "3      3691 2018-04-26 11:43:05     Dinner          NS   \n",
       "4      4094 2018-04-10 11:12:40  Breakfast          NS   \n",
       "\n",
       "                                         order_items  order_price   \n",
       "0                           [(Fries, 6), (Salad, 4)]       140.80  \\\n",
       "1                        [(Cereal, 8), (Pancake, 6)]       313.50   \n",
       "2  [(Steak, 3), (Salad, 1), (Chicken, 6), (Fries,...       714.00   \n",
       "3            [(Pancake, 9), (Eggs, 10), (Cereal, 2)]       480.25   \n",
       "4  [(Eggs, 5), (Coffee, 3), (Pancake, 9), (Cereal...       497.75   \n",
       "\n",
       "   customer_loyalty  distance_to_customer_km  delivery_fee   location   \n",
       "0              True                    8.335         13.70  Docklands  \\\n",
       "1              True                    7.536          6.17  Melbourne   \n",
       "2             False                    9.860         15.09   Richmond   \n",
       "3             False                    8.614         13.68  Southbank   \n",
       "4             False                    8.802         13.76  Southbank   \n",
       "\n",
       "           updated_at  \n",
       "0 2023-07-06 02:00:00  \n",
       "1 2023-07-06 02:00:00  \n",
       "2 2023-07-06 02:00:00  \n",
       "3 2023-07-06 02:00:00  \n",
       "4 2023-07-06 02:00:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f96806a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Define directory\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m directory \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpardir, \u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Create target directory if it doesn't exist\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(directory):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Define directory\n",
    "directory = os.path.join(os.pardir, 'data')\n",
    "\n",
    "# Create target directory if it doesn't exist\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Save file\n",
    "df_clean.to_csv(os.path.join(directory, 'clean_data.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54fc64ae",
   "metadata": {},
   "source": [
    "### Step 1.3: Feature Engineering\n",
    "\n",
    "- Here we will be creating new columns from existing columns."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1327cc2d",
   "metadata": {},
   "source": [
    "#### Step 1.4: Feature Engineering ( `order_items` )\n",
    "\n",
    "- Here we will be extracting the food items and their quantities from the `order_items` column into separate columns.\n",
    "- `cuisine` which will be the type of cuisine the food item is.\n",
    "-  `order_items_count` which will be the total number of items ordered.\n",
    "-  `order_items_total` which will be the total price of the items ordered."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16a06931",
   "metadata": {},
   "source": [
    "#### Step 1.5: Feature Engineering ( `order_date` )\n",
    "\n",
    "- Here we will be creating new columns based on the existing columns in the dataset.\n",
    "- `order_time_of_day` which will be the hour of the day the order was made. (Morning, Afternoon, Evening, Night)\n",
    "- `order_day` which will be the day of the week the order was made. (Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday)\n",
    "-  `order_month` which will be the month of the year the order was made. (January, February, March, April, May, June, July, August, September, October, November, December)\n",
    "- `order_season` which will be the season the order was made. (Summer, Autumn, Winter, Spring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ff07fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_en(df_clean):\n",
    "    # Create a copy of the DataFrame to avoid modifying the original one\n",
    "    df = df_clean.copy()\n",
    "\n",
    "   # Explode the 'order_items' column\n",
    "    df_exploded = df.explode('order_items')\n",
    "\n",
    "    # Split the tuple into two new columns\n",
    "    df_exploded[['cuisine', 'quantity_ordered']] = pd.DataFrame(df_exploded['order_items'].tolist(), index=df_exploded.index)\n",
    "\n",
    "    # average_order_price = order_items_total / quantity_ordered\n",
    "    df_exploded['average_item_price'] = df_exploded['order_price'] / df_exploded['quantity_ordered']\n",
    "\n",
    "    # two decimal places\n",
    "    df_exploded['average_item_price'] = df_exploded['average_item_price'].round(2)\n",
    "\n",
    "    # Drop the 'order_items' column\n",
    "    df_exploded.drop('order_items', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    # Extract the year, month as Jan, Feb, Mar, etc. Add them as new columns\n",
    "    df_exploded['order_month'] = df_exploded['order_date'].dt.strftime('%b')\n",
    "    df_exploded['day_of_week'] = df_exploded['order_date'].dt.strftime('%a')\n",
    "\n",
    "    # new column for the season the order was made. (Spring, Summer, Autumn, Winter)\n",
    "    df_exploded['order_season'] = df_exploded['order_date'].dt.month.apply(lambda x: (x%12 + 3)//3)\n",
    "    \n",
    "    # change the season number to season name\n",
    "    df_exploded['order_season'] = df_exploded['order_season'].map({1:'Spring', 2:'Summer', 3:'Autumn', 4:'Winter'})\n",
    "\n",
    "    # reposition the columns \n",
    "    df_exploded = df_exploded[['order_id', 'order_date' , 'order_price', 'quantity_ordered' , 'average_item_price', 'order_month', 'day_of_week', 'order_season' , 'order_type', 'branch_code' , 'delivery_fee', 'location', 'cuisine' , 'customer_loyalty', 'distance_to_customer_km','updated_at']]\n",
    "\n",
    "    return df_exploded\n",
    "\n",
    "df_exploded = feature_en(df_clean)\n",
    "df_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2983b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad4009a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eafb9790",
   "metadata": {},
   "source": [
    "### Step 2: Descriptive Statistics \n",
    "\n",
    "- Descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset's distribution, excluding NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebbddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistics\n",
    "df_exploded.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d5a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base on the information from the describe() method:\n",
    "\n",
    "#  Orders Date Range \n",
    "print('Orders Date Range ---->: ', df_exploded['order_date'].min(), 'to', df_exploded['order_date'].max())\n",
    "\n",
    "# Order Price Range\n",
    "print('Order Price Range ---->: ', df_exploded['order_price'].min(), 'to', df_exploded['order_price'].max())\n",
    "\n",
    "# Average Order Price in 2 decimal places\n",
    "print('Average Order Price ---->: ', round(df_exploded['order_price'].mean(), 2))\n",
    "\n",
    "# Popular Order Type\n",
    "print('Popular Order Type ---->: ', df_exploded['order_type'].mode()[0])\n",
    "\n",
    "# Popular Cuisine\n",
    "print('Popular Cuisine ---->: ', df_exploded['cuisine'].mode()[0])\n",
    "\n",
    "# Popular Branch\n",
    "print('Popular Branch ---->: ', df_exploded['branch_code'].mode()[0])\n",
    "\n",
    "# Popular Day of the Week\n",
    "print('Popular Day of the Week ---->: ', df_exploded['day_of_week'].mode()[0])\n",
    "\n",
    "# Popular Season\n",
    "print('Popular Season ---->: ', df_exploded['order_season'].mode()[0])\n",
    "\n",
    "# Popular Month\n",
    "print('Popular Month ---->: ', df_exploded['order_month'].mode()[0])\n",
    "\n",
    "# Pupluar Hour\n",
    "print('Popular Hour ---->: ', df_exploded['order_date'].dt.hour.mode()[0])\n",
    "\n",
    "# Delivery Fee Range\n",
    "print('Delivery Fee Range ---->: ', df_exploded['delivery_fee'].min(), 'to', df_exploded['delivery_fee'].max())\n",
    "\n",
    "# Average Disance to Customer in 2 decimal places\n",
    "print('Average Disance to Customer ---->: ', round(df_exploded['distance_to_customer_km'].mean(), 2))\n",
    "\n",
    "# Popular Location\n",
    "print('Popular Location ---->: ', df_exploded['location'].mode()[0])\n",
    "\n",
    "# Types of cuisine\n",
    "print('Types of cuisine ---->: ', df_exploded['cuisine'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040323ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b98b1a3",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1118595b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2f8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba33aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
