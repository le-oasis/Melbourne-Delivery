{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f445c1e-b119-4f5e-b580-c01df1b72b6c",
   "metadata": {
    "id": "9f445c1e-b119-4f5e-b580-c01df1b72b6c"
   },
   "source": [
    "# About The Dataset\n",
    "\n",
    "- The dataset contains Food Delivery data from a restaurant in Melbourne, Australia. ​The restaurant has three branches around the CBD area. All three branches share the same menu but they have different management so they operate differently.\n",
    "\n",
    "## Data Dictionary:\n",
    "\n",
    "- `order_id` - A unique id for each order.\n",
    "- `date` - The date the order was made, given in YYYY-MM-DD format.\n",
    "- `time` - The time the order was made, given in hh:mm:ss format.\n",
    "- `order_type` - A categorical attribute representing the different types of orders namely: Breakfast, Lunch or Dinner.\n",
    "- `branch_code` - A categorical attribute representing the branch code inwhich the order was made. Branch information is given in the `​branches.csv` file.\n",
    "- `order_items` - A list of tuples representing the order items: first element of the tuple is the item ordered, and the second element is the quantity ordered for such item.\n",
    "- `order_price` - A float value representing the order total price.\n",
    "- `customer_lat` - Latitude of the customer coming from the `​nodes.csv` ​ file.\n",
    "- `customer_lon` - Longitude of the customer coming from the `​nodes.csv`file.\n",
    "- ` customerHasloyalty?` - A logical variable denoting whether the customer has a loyalty card with the restaurant (1 if the customer has loyalty and 0 otherwise).\n",
    "- `distance_to_customer_KM` - A float representing the shortest distance, in kilometers, between the branch and the customer nodes with respect to the ​nodes.csv​ and the `​edges.csv` ​ files.\n",
    "\n",
    "​Dijkstra algorithm ​ can be used to find the shortest path between two nodes in a graph.\n",
    "\n",
    "\n",
    "- `delivery_fee` - A float representing the delivery fee of the order.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63197e06-f419-4a08-b54d-c2c03eec9883",
   "metadata": {
    "id": "63197e06-f419-4a08-b54d-c2c03eec9883"
   },
   "source": [
    "## Project Goals \n",
    "\n",
    "- Write a python script to transform the data into a usable format for a BI Analyst.\n",
    "\n",
    "    -  The transformation can generate more than one table if needed.\n",
    "\n",
    "- Analyze the data.\n",
    "\n",
    "    -  Highlight critical errors that need to be corrected before the BI analyst can make use of the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f9faae4-1e3e-48ba-a3cd-d6970db40272",
   "metadata": {
    "id": "2f9faae4-1e3e-48ba-a3cd-d6970db40272"
   },
   "source": [
    "## Step 0: Initiate Libraries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c231464-4a4b-4a66-8321-f96302dc09e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T14:45:29.892708Z",
     "start_time": "2023-07-04T14:45:29.731937Z"
    },
    "id": "0c231464-4a4b-4a66-8321-f96302dc09e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "\n",
    "# Import Key Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Import Data Preprocessing Libraries\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# ast : Abstract Syntax Trees\n",
    "from ast import literal_eval\n",
    "\n",
    "# Import Geospatial Libraries\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from geopy.distance import geodesic\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import *\n",
    "import reverse_geocoder as rg \n",
    "\n",
    "# Datetime\n",
    "import datetime\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "# Data Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "import plotly.graph_objs as go\n",
    "from plotly.tools import FigureFactory as FF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34a3830a-cb7f-48ea-8e25-3c4aa759032e",
   "metadata": {
    "id": "34a3830a-cb7f-48ea-8e25-3c4aa759032e"
   },
   "source": [
    "## Step 1: Read Data\n",
    "\n",
    "- Here will we be reading the raw data as -  `dirty_data.csv` file into our jupyter notebook.\n",
    "- The variable name for the Food Delivery data would be called `dataset` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633453ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T14:45:29.903414Z",
     "start_time": "2023-07-04T14:45:29.893924Z"
    },
    "id": "633453ac",
    "tags": []
   },
   "outputs": [],
   "source": [
    "delivery_data = pd.read_csv('data/dirty_data.csv')\n",
    "\n",
    "# Copy the data\n",
    "orders_df = delivery_data.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18a20a56-37c2-4dfb-8f66-28142e01931e",
   "metadata": {
    "id": "18a20a56-37c2-4dfb-8f66-28142e01931e"
   },
   "source": [
    "### Step 1.1: Data Discovery (Building Intuition)\n",
    "\n",
    "- This is a technique we use to get an initial feel for our data tables.\n",
    "- We read the data using pandas and perform method calls.\n",
    "- Standardize dataset columns in the correct format.\n",
    "- Explore Descriptive Statistics on Numerical Columns and more below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63e102aa",
   "metadata": {
    "id": "63e102aa"
   },
   "source": [
    "##### `df.info()`\n",
    "\n",
    "- It is an important and widely used method of Python.\n",
    "- This Method prints the information or summary of the dataframe.\n",
    "- It prints the various information of the Dataframe such as index type, dtype, columns, non-values, and memory usage. It gives a quick overview of the dataset.\n",
    "- Info Method to get the Non-Null Count & Dtype (data type) of the dataset,\n",
    "- Validate if a column and column type aligns with the format of the Business Requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c083d1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T14:45:29.955377Z",
     "start_time": "2023-07-04T14:45:29.922555Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c083d1a",
    "outputId": "2283d68b-902c-45d7-d0e1-f39f87c8390c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   order_id                 500 non-null    object \n",
      " 1   date                     500 non-null    object \n",
      " 2   time                     500 non-null    object \n",
      " 3   order_type               500 non-null    object \n",
      " 4   branch_code              500 non-null    object \n",
      " 5   order_items              500 non-null    object \n",
      " 6   order_price              500 non-null    float64\n",
      " 7   customer_lat             500 non-null    float64\n",
      " 8   customer_lon             500 non-null    float64\n",
      " 9   customerHasloyalty?      500 non-null    int64  \n",
      " 10  distance_to_customer_KM  500 non-null    float64\n",
      " 11  delivery_fee             500 non-null    float64\n",
      "dtypes: float64(5), int64(1), object(6)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "orders_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a0164e1",
   "metadata": {
    "id": "2a0164e1"
   },
   "source": [
    "Based on this information above:\n",
    "\n",
    "- The dataset has 500 rows and 12 columns.\n",
    "- The dataset has 0 null values.\n",
    "\n",
    "\n",
    "Data transformations and cleaning tasks that might be needed include:\n",
    "\n",
    "- Checking the data type of all columns to make sure they are in the appropriate format for analysis.\n",
    "- The `order_id`, `date`, `time`, `order_type`, `branch_code`, `order_items` columns datatypes need to be changed.\n",
    "- The `date` &  `time` need to be merged into a single column, renamed to `order_date` and converted to `datetime` dtype format for Parsing Dates.\n",
    "- Extracting the food items and their quantities from the `order_items` column into separate columns.\n",
    "- Checking the category column entries for case sensitivity (Checking if the values in the branch_code and order_type columns are consistent and correctly labeled.)\n",
    "- feature engineer the `order_date`  column, potentially separating them into year, month, day, and hour columns.\n",
    "- Removing any unnecessary or irrelevant columns.\n",
    "- Checking for outliers in numerical columns such as order_price, distance_to_customer_KM, and delivery_fee.\n",
    "- Checking if the customerHasloyalty? column only contains binary values (0 and 1).\n",
    "- Checking if the  `distance_to_customer_KM` column is consistent with the values in the `nodes.csv` file.\n",
    "- Checking if the `delivery_fee` column is consistent with the values in the `edges.csv`  file.\n",
    "- Checking if the `order_price` column is consistent with the values in the `order_items`  column.\n",
    "- Checking if the `order_price` column is consistent with the values in the  `delivery_fee` column.\n",
    "\n",
    "\n",
    "Remember, the goal of this process is to ensure that your dataset is clean, understandable, and ready for further Business Intelligence analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458dc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bFjYKlKRSj4-",
   "metadata": {
    "id": "bFjYKlKRSj4-"
   },
   "source": [
    "### Step 1.2: Data Preporcessing - Cleaning \n",
    "\n",
    "- Here we will be cleaning the data by converting the columns to the correct data types.\n",
    "- We will merge the date and time columns into one column called `order_date` and convert it to a datetime type.\n",
    "- We will also rename the `customerHasloyalty?` , `distance_to_customer_KM` columns to `customer_loyalty` , and  `distance_to_customer` respectively.\n",
    "- We will add an additional column called `updated at` which will be the date and time the data was updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eNo-KF7Sj1V",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T14:45:38.184964Z",
     "start_time": "2023-07-04T14:45:38.169814Z"
    },
    "id": "4eNo-KF7Sj1V",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   order_id                 500 non-null    int64         \n",
      " 1   order_date               500 non-null    datetime64[ns]\n",
      " 2   order_type               500 non-null    category      \n",
      " 3   branch_code              500 non-null    category      \n",
      " 4   order_items              500 non-null    object        \n",
      " 5   order_price              500 non-null    float64       \n",
      " 6   customer_loyalty         500 non-null    bool          \n",
      " 7   distance_to_customer_km  500 non-null    float64       \n",
      " 8   delivery_fee             500 non-null    float64       \n",
      " 9   location                 500 non-null    object        \n",
      " 10  updated_at               500 non-null    datetime64[ns]\n",
      "dtypes: bool(1), category(2), datetime64[ns](2), float64(3), int64(1), object(2)\n",
      "memory usage: 33.1+ KB\n"
     ]
    }
   ],
   "source": [
    "def reverseGeocode(coordinates): \n",
    "    result = rg.search(coordinates)\n",
    "    return (result)\n",
    "\n",
    "def cleaning_data_types(orders_df):\n",
    "    # Create a copy of the DataFrame to avoid modifying the original one\n",
    "    df_clean = orders_df.copy()\n",
    "\n",
    "    # Define helper function to clean date data\n",
    "    def clean_date(date_str):\n",
    "        date_str = date_str.strip()\n",
    "        date = parse(date_str, dayfirst=True)  # dayfirst=True to handle DD/MM/YYYY properly\n",
    "        return date.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Convert columns to appropriate data types\n",
    "    df_clean['order_id'] = df_clean['order_id'].str.extract('(\\d+)').astype(int)\n",
    "    df_clean['date'] = df_clean['date'].apply(clean_date).astype('datetime64[ns]')\n",
    "    df_clean['datetime'] = pd.to_datetime(df_clean['date'].astype(str) + ' ' + df_clean['time'])\n",
    "    df_clean[\"order_type\"] = df_clean[\"order_type\"].astype(\"category\")\n",
    "\n",
    "   \n",
    "    # Convert 'branch_code' to upper case to handle case-insensitive duplicates\n",
    "    df_clean[\"branch_code\"] = df_clean[\"branch_code\"].str.upper().astype(\"category\")\n",
    "\n",
    "\n",
    "    # Use exception handling for potential errors in the literal_eval() function\n",
    "    try:\n",
    "        df_clean[\"order_items\"] = df_clean[\"order_items\"].apply(literal_eval)\n",
    "    except (ValueError, SyntaxError):\n",
    "        pass\n",
    "\n",
    "    # Continue with the remaining conversions\n",
    "    df_clean[\"order_price\"] = df_clean[\"order_price\"].astype(float)\n",
    "    df_clean[\"customer_lat\"] = df_clean[\"customer_lat\"].astype(float)\n",
    "    df_clean[\"customer_lon\"] = df_clean[\"customer_lon\"].astype(float)\n",
    "    df_clean[\"customerHasloyalty?\"] = df_clean[\"customerHasloyalty?\"].astype(bool)\n",
    "    df_clean[\"distance_to_customer_KM\"] = df_clean[\"distance_to_customer_KM\"].astype(float)\n",
    "    df_clean[\"delivery_fee\"] = df_clean[\"delivery_fee\"].astype(float)\n",
    "\n",
    "\n",
    "    # make the order_price two decimal places\n",
    "    df_clean['order_price'] = df_clean['order_price'].round(2)\n",
    "\n",
    "    # make the delivery fee two decimal places\n",
    "    df_clean['delivery_fee'] = df_clean['delivery_fee'].round(2)\n",
    "\n",
    "\n",
    "    # transform long/lat into state\n",
    "    coordinates =list(zip(df_clean['customer_lat'],df_clean['customer_lon'])) # generates pair of (lat,long)\n",
    "    data = reverseGeocode(coordinates)\n",
    "\n",
    "\n",
    "    # Create a new column with the City name    \n",
    "    df_clean['name'] = [i['name'] for i in data]\n",
    "    df_clean['admin1'] = [i['admin1'] for i in data]\n",
    "    df_clean['admin2'] = [i['admin2'] for i in data]\n",
    "\n",
    "\n",
    "    df_clean.drop(['admin1', 'admin2'], axis=1, inplace=True)\n",
    "    df_clean.rename(columns={'name': 'location'}, inplace=True)\n",
    " \n",
    "\n",
    "    # Rename the customerHasloyalty? column to customerHasloyalty\n",
    "    df_clean.rename(columns={'customerHasloyalty?': 'customer_loyalty'}, inplace=True)\n",
    "\n",
    "    # Rename the distance_to_customer_KM column to distance_to_customer_km\n",
    "    df_clean.rename(columns={'distance_to_customer_KM': 'distance_to_customer_km'}, inplace=True)\n",
    "\n",
    "    # Drop the 'date' and 'time' columns\n",
    "    df_clean.drop(['date', 'time'], axis=1, inplace=True)\n",
    "\n",
    "    # Rename the 'datetime' column to 'order_date' and move it to the second position\n",
    "    df_clean.rename(columns={'datetime': 'order_date'}, inplace=True)\n",
    "    order_date = df_clean.pop('order_date')\n",
    "    df_clean.insert(1, 'order_date', order_date)\n",
    "\n",
    "    # Add the 'updated_at' column with the current datetime\n",
    "    df_clean['updated_at'] = datetime.datetime.today().replace(second=0, microsecond=0)\n",
    "\n",
    "    df_clean.drop(['customer_lat', 'customer_lon'], axis=1, inplace=True)\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "df_clean = cleaning_data_types(orders_df)\n",
    "df_clean.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f6f7de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>order_type</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>order_items</th>\n",
       "      <th>order_price</th>\n",
       "      <th>customer_loyalty</th>\n",
       "      <th>distance_to_customer_km</th>\n",
       "      <th>delivery_fee</th>\n",
       "      <th>location</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1406</td>\n",
       "      <td>2018-07-08 15:16:03</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Fries, 6), (Salad, 4)]</td>\n",
       "      <td>140.80</td>\n",
       "      <td>True</td>\n",
       "      <td>8.335</td>\n",
       "      <td>13.70</td>\n",
       "      <td>Docklands</td>\n",
       "      <td>2023-07-06 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10125</td>\n",
       "      <td>2018-12-01 08:20:16</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Cereal, 8), (Pancake, 6)]</td>\n",
       "      <td>313.50</td>\n",
       "      <td>True</td>\n",
       "      <td>7.536</td>\n",
       "      <td>6.17</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>2023-07-06 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4175</td>\n",
       "      <td>2018-06-07 14:05:04</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Steak, 3), (Salad, 1), (Chicken, 6), (Fries,...</td>\n",
       "      <td>714.00</td>\n",
       "      <td>False</td>\n",
       "      <td>9.860</td>\n",
       "      <td>15.09</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>2023-07-06 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3691</td>\n",
       "      <td>2018-04-26 11:43:05</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Pancake, 9), (Eggs, 10), (Cereal, 2)]</td>\n",
       "      <td>480.25</td>\n",
       "      <td>False</td>\n",
       "      <td>8.614</td>\n",
       "      <td>13.68</td>\n",
       "      <td>Southbank</td>\n",
       "      <td>2023-07-06 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4094</td>\n",
       "      <td>2018-04-10 11:12:40</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Eggs, 5), (Coffee, 3), (Pancake, 9), (Cereal...</td>\n",
       "      <td>497.75</td>\n",
       "      <td>False</td>\n",
       "      <td>8.802</td>\n",
       "      <td>13.76</td>\n",
       "      <td>Southbank</td>\n",
       "      <td>2023-07-06 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10193</td>\n",
       "      <td>2018-10-15 17:27:53</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>TP</td>\n",
       "      <td>[(Fish&amp;Chips, 5), (Shrimp, 5), (Salmon, 2), (P...</td>\n",
       "      <td>664.50</td>\n",
       "      <td>False</td>\n",
       "      <td>9.081</td>\n",
       "      <td>13.39</td>\n",
       "      <td>Kamaishi</td>\n",
       "      <td>2023-07-06 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>958</td>\n",
       "      <td>2018-05-25 12:43:56</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BK</td>\n",
       "      <td>[(Salad, 2), (Steak, 7), (Chicken, 2)]</td>\n",
       "      <td>413.40</td>\n",
       "      <td>False</td>\n",
       "      <td>6.412</td>\n",
       "      <td>12.01</td>\n",
       "      <td>Collingwood</td>\n",
       "      <td>2023-07-06 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3630</td>\n",
       "      <td>2018-09-30 16:57:27</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Shrimp, 8), (Fish&amp;Chips, 6), (Salmon, 4), (P...</td>\n",
       "      <td>998.50</td>\n",
       "      <td>False</td>\n",
       "      <td>7.759</td>\n",
       "      <td>16.25</td>\n",
       "      <td>Kamaishi</td>\n",
       "      <td>2023-07-06 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5755</td>\n",
       "      <td>2018-07-03 10:01:41</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Cereal, 1), (Coffee, 7), (Pancake, 3)]</td>\n",
       "      <td>146.25</td>\n",
       "      <td>False</td>\n",
       "      <td>8.996</td>\n",
       "      <td>14.11</td>\n",
       "      <td>East Melbourne</td>\n",
       "      <td>2023-07-06 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8573</td>\n",
       "      <td>2018-04-21 11:32:57</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Eggs, 7), (Cereal, 8), (Pancake, 3), (Coffee...</td>\n",
       "      <td>417.25</td>\n",
       "      <td>False</td>\n",
       "      <td>8.624</td>\n",
       "      <td>15.76</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>2023-07-06 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6221</td>\n",
       "      <td>2018-09-03 10:11:49</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Eggs, 6), (Cereal, 10)]</td>\n",
       "      <td>658.40</td>\n",
       "      <td>False</td>\n",
       "      <td>8.163</td>\n",
       "      <td>12.82</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>2023-07-06 01:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id          order_date order_type branch_code   \n",
       "0       1406 2018-07-08 15:16:03      Lunch          NS  \\\n",
       "1      10125 2018-12-01 08:20:16  Breakfast          NS   \n",
       "2       4175 2018-06-07 14:05:04      Lunch          NS   \n",
       "3       3691 2018-04-26 11:43:05     Dinner          NS   \n",
       "4       4094 2018-04-10 11:12:40  Breakfast          NS   \n",
       "5      10193 2018-10-15 17:27:53     Dinner          TP   \n",
       "6        958 2018-05-25 12:43:56  Breakfast          BK   \n",
       "7       3630 2018-09-30 16:57:27     Dinner          NS   \n",
       "8       5755 2018-07-03 10:01:41  Breakfast          NS   \n",
       "9       8573 2018-04-21 11:32:57  Breakfast          NS   \n",
       "10      6221 2018-09-03 10:11:49  Breakfast          NS   \n",
       "\n",
       "                                          order_items  order_price   \n",
       "0                            [(Fries, 6), (Salad, 4)]       140.80  \\\n",
       "1                         [(Cereal, 8), (Pancake, 6)]       313.50   \n",
       "2   [(Steak, 3), (Salad, 1), (Chicken, 6), (Fries,...       714.00   \n",
       "3             [(Pancake, 9), (Eggs, 10), (Cereal, 2)]       480.25   \n",
       "4   [(Eggs, 5), (Coffee, 3), (Pancake, 9), (Cereal...       497.75   \n",
       "5   [(Fish&Chips, 5), (Shrimp, 5), (Salmon, 2), (P...       664.50   \n",
       "6              [(Salad, 2), (Steak, 7), (Chicken, 2)]       413.40   \n",
       "7   [(Shrimp, 8), (Fish&Chips, 6), (Salmon, 4), (P...       998.50   \n",
       "8            [(Cereal, 1), (Coffee, 7), (Pancake, 3)]       146.25   \n",
       "9   [(Eggs, 7), (Cereal, 8), (Pancake, 3), (Coffee...       417.25   \n",
       "10                          [(Eggs, 6), (Cereal, 10)]       658.40   \n",
       "\n",
       "    customer_loyalty  distance_to_customer_km  delivery_fee        location   \n",
       "0               True                    8.335         13.70       Docklands  \\\n",
       "1               True                    7.536          6.17       Melbourne   \n",
       "2              False                    9.860         15.09        Richmond   \n",
       "3              False                    8.614         13.68       Southbank   \n",
       "4              False                    8.802         13.76       Southbank   \n",
       "5              False                    9.081         13.39        Kamaishi   \n",
       "6              False                    6.412         12.01     Collingwood   \n",
       "7              False                    7.759         16.25        Kamaishi   \n",
       "8              False                    8.996         14.11  East Melbourne   \n",
       "9              False                    8.624         15.76       Melbourne   \n",
       "10             False                    8.163         12.82       Melbourne   \n",
       "\n",
       "            updated_at  \n",
       "0  2023-07-06 01:30:00  \n",
       "1  2023-07-06 01:30:00  \n",
       "2  2023-07-06 01:30:00  \n",
       "3  2023-07-06 01:30:00  \n",
       "4  2023-07-06 01:30:00  \n",
       "5  2023-07-06 01:30:00  \n",
       "6  2023-07-06 01:30:00  \n",
       "7  2023-07-06 01:30:00  \n",
       "8  2023-07-06 01:30:00  \n",
       "9  2023-07-06 01:30:00  \n",
       "10 2023-07-06 01:30:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f96806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('clean_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54fc64ae",
   "metadata": {},
   "source": [
    "### Step 1.3: Feature Engineering\n",
    "\n",
    "- Here we will be creating new columns from existing columns."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1327cc2d",
   "metadata": {},
   "source": [
    "#### Step 1.4: Feature Engineering ( `order_items` )\n",
    "\n",
    "- Here we will be extracting the food items and their quantities from the `order_items` column into separate columns.\n",
    "- `cuisine` which will be the type of cuisine the food item is.\n",
    "-  `order_items_count` which will be the total number of items ordered.\n",
    "-  `order_items_total` which will be the total price of the items ordered."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16a06931",
   "metadata": {},
   "source": [
    "#### Step 1.5: Feature Engineering ( `order_date` )\n",
    "\n",
    "- Here we will be creating new columns based on the existing columns in the dataset.\n",
    "- `order_time_of_day` which will be the hour of the day the order was made. (Morning, Afternoon, Evening, Night)\n",
    "- `order_day` which will be the day of the week the order was made. (Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday)\n",
    "-  `order_month` which will be the month of the year the order was made. (January, February, March, April, May, June, July, August, September, October, November, December)\n",
    "- `order_season` which will be the season the order was made. (Summer, Autumn, Winter, Spring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ff07fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>order_price</th>\n",
       "      <th>quantity_ordered</th>\n",
       "      <th>average_item_price</th>\n",
       "      <th>order_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>order_season</th>\n",
       "      <th>order_type</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>delivery_fee</th>\n",
       "      <th>location</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>customer_loyalty</th>\n",
       "      <th>distance_to_customer_km</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1406</td>\n",
       "      <td>2018-07-08 15:16:03</td>\n",
       "      <td>140.8</td>\n",
       "      <td>6</td>\n",
       "      <td>23.47</td>\n",
       "      <td>Jul</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>13.70</td>\n",
       "      <td>Docklands</td>\n",
       "      <td>Fries</td>\n",
       "      <td>True</td>\n",
       "      <td>8.335</td>\n",
       "      <td>2023-07-06 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1406</td>\n",
       "      <td>2018-07-08 15:16:03</td>\n",
       "      <td>140.8</td>\n",
       "      <td>4</td>\n",
       "      <td>35.20</td>\n",
       "      <td>Jul</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>13.70</td>\n",
       "      <td>Docklands</td>\n",
       "      <td>Salad</td>\n",
       "      <td>True</td>\n",
       "      <td>8.335</td>\n",
       "      <td>2023-07-06 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10125</td>\n",
       "      <td>2018-12-01 08:20:16</td>\n",
       "      <td>313.5</td>\n",
       "      <td>8</td>\n",
       "      <td>39.19</td>\n",
       "      <td>Dec</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>6.17</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Cereal</td>\n",
       "      <td>True</td>\n",
       "      <td>7.536</td>\n",
       "      <td>2023-07-06 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10125</td>\n",
       "      <td>2018-12-01 08:20:16</td>\n",
       "      <td>313.5</td>\n",
       "      <td>6</td>\n",
       "      <td>52.25</td>\n",
       "      <td>Dec</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>6.17</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Pancake</td>\n",
       "      <td>True</td>\n",
       "      <td>7.536</td>\n",
       "      <td>2023-07-06 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4175</td>\n",
       "      <td>2018-06-07 14:05:04</td>\n",
       "      <td>714.0</td>\n",
       "      <td>3</td>\n",
       "      <td>238.00</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Thu</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>15.09</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Steak</td>\n",
       "      <td>False</td>\n",
       "      <td>9.860</td>\n",
       "      <td>2023-07-06 01:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id          order_date  order_price  quantity_ordered   \n",
       "0      1406 2018-07-08 15:16:03        140.8                 6  \\\n",
       "0      1406 2018-07-08 15:16:03        140.8                 4   \n",
       "1     10125 2018-12-01 08:20:16        313.5                 8   \n",
       "1     10125 2018-12-01 08:20:16        313.5                 6   \n",
       "2      4175 2018-06-07 14:05:04        714.0                 3   \n",
       "\n",
       "   average_item_price order_month day_of_week order_season order_type   \n",
       "0               23.47         Jul         Sun       Autumn      Lunch  \\\n",
       "0               35.20         Jul         Sun       Autumn      Lunch   \n",
       "1               39.19         Dec         Sat       Spring  Breakfast   \n",
       "1               52.25         Dec         Sat       Spring  Breakfast   \n",
       "2              238.00         Jun         Thu       Autumn      Lunch   \n",
       "\n",
       "  branch_code  delivery_fee   location  cuisine  customer_loyalty   \n",
       "0          NS         13.70  Docklands    Fries              True  \\\n",
       "0          NS         13.70  Docklands    Salad              True   \n",
       "1          NS          6.17  Melbourne   Cereal              True   \n",
       "1          NS          6.17  Melbourne  Pancake              True   \n",
       "2          NS         15.09   Richmond    Steak             False   \n",
       "\n",
       "   distance_to_customer_km          updated_at  \n",
       "0                    8.335 2023-07-06 01:30:00  \n",
       "0                    8.335 2023-07-06 01:30:00  \n",
       "1                    7.536 2023-07-06 01:30:00  \n",
       "1                    7.536 2023-07-06 01:30:00  \n",
       "2                    9.860 2023-07-06 01:30:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_en(df_clean):\n",
    "    # Create a copy of the DataFrame to avoid modifying the original one\n",
    "    df = df_clean.copy()\n",
    "\n",
    "   # Explode the 'order_items' column\n",
    "    df_exploded = df.explode('order_items')\n",
    "\n",
    "    # Split the tuple into two new columns\n",
    "    df_exploded[['cuisine', 'quantity_ordered']] = pd.DataFrame(df_exploded['order_items'].tolist(), index=df_exploded.index)\n",
    "\n",
    "    # average_order_price = order_items_total / quantity_ordered\n",
    "    df_exploded['average_item_price'] = df_exploded['order_price'] / df_exploded['quantity_ordered']\n",
    "\n",
    "    # two decimal places\n",
    "    df_exploded['average_item_price'] = df_exploded['average_item_price'].round(2)\n",
    "\n",
    "    # Drop the 'order_items' column\n",
    "    df_exploded.drop('order_items', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    # Extract the year, month as Jan, Feb, Mar, etc. Add them as new columns\n",
    "    df_exploded['order_month'] = df_exploded['order_date'].dt.strftime('%b')\n",
    "    df_exploded['day_of_week'] = df_exploded['order_date'].dt.strftime('%a')\n",
    "\n",
    "    # new column for the season the order was made. (Spring, Summer, Autumn, Winter)\n",
    "    df_exploded['order_season'] = df_exploded['order_date'].dt.month.apply(lambda x: (x%12 + 3)//3)\n",
    "    \n",
    "    # change the season number to season name\n",
    "    df_exploded['order_season'] = df_exploded['order_season'].map({1:'Spring', 2:'Summer', 3:'Autumn', 4:'Winter'})\n",
    "\n",
    "    # reposition the columns \n",
    "    df_exploded = df_exploded[['order_id', 'order_date' , 'order_price', 'quantity_ordered' , 'average_item_price', 'order_month', 'day_of_week', 'order_season' , 'order_type', 'branch_code' , 'delivery_fee', 'location', 'cuisine' , 'customer_loyalty', 'distance_to_customer_km','updated_at']]\n",
    "\n",
    "    return df_exploded\n",
    "\n",
    "df_exploded = feature_en(df_clean)\n",
    "df_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2983b0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1596 entries, 0 to 499\n",
      "Data columns (total 16 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   order_id                 1596 non-null   int64         \n",
      " 1   order_date               1596 non-null   datetime64[ns]\n",
      " 2   order_price              1596 non-null   float64       \n",
      " 3   quantity_ordered         1596 non-null   int64         \n",
      " 4   average_item_price       1596 non-null   float64       \n",
      " 5   order_month              1596 non-null   object        \n",
      " 6   day_of_week              1596 non-null   object        \n",
      " 7   order_season             1596 non-null   object        \n",
      " 8   order_type               1596 non-null   category      \n",
      " 9   branch_code              1596 non-null   category      \n",
      " 10  delivery_fee             1596 non-null   float64       \n",
      " 11  location                 1596 non-null   object        \n",
      " 12  cuisine                  1596 non-null   object        \n",
      " 13  customer_loyalty         1596 non-null   bool          \n",
      " 14  distance_to_customer_km  1596 non-null   float64       \n",
      " 15  updated_at               1596 non-null   datetime64[ns]\n",
      "dtypes: bool(1), category(2), datetime64[ns](2), float64(4), int64(2), object(5)\n",
      "memory usage: 179.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_exploded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad4009a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eafb9790",
   "metadata": {},
   "source": [
    "### Step 2: Descriptive Statistics \n",
    "\n",
    "- Descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset's distribution, excluding NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebbddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistics\n",
    "df_exploded.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d5a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base on the information from the describe() method:\n",
    "\n",
    "#  Orders Date Range \n",
    "print('Orders Date Range ---->: ', df_exploded['order_date'].min(), 'to', df_exploded['order_date'].max())\n",
    "\n",
    "# Order Price Range\n",
    "print('Order Price Range ---->: ', df_exploded['order_price'].min(), 'to', df_exploded['order_price'].max())\n",
    "\n",
    "# Average Order Price in 2 decimal places\n",
    "print('Average Order Price ---->: ', round(df_exploded['order_price'].mean(), 2))\n",
    "\n",
    "# Popular Order Type\n",
    "print('Popular Order Type ---->: ', df_exploded['order_type'].mode()[0])\n",
    "\n",
    "# Popular Cuisine\n",
    "print('Popular Cuisine ---->: ', df_exploded['cuisine'].mode()[0])\n",
    "\n",
    "# Popular Branch\n",
    "print('Popular Branch ---->: ', df_exploded['branch_code'].mode()[0])\n",
    "\n",
    "# Popular Day of the Week\n",
    "print('Popular Day of the Week ---->: ', df_exploded['day_of_week'].mode()[0])\n",
    "\n",
    "# Popular Season\n",
    "print('Popular Season ---->: ', df_exploded['order_season'].mode()[0])\n",
    "\n",
    "# Popular Month\n",
    "print('Popular Month ---->: ', df_exploded['order_month'].mode()[0])\n",
    "\n",
    "# Pupluar Hour\n",
    "print('Popular Hour ---->: ', df_exploded['order_date'].dt.hour.mode()[0])\n",
    "\n",
    "# Delivery Fee Range\n",
    "print('Delivery Fee Range ---->: ', df_exploded['delivery_fee'].min(), 'to', df_exploded['delivery_fee'].max())\n",
    "\n",
    "# Average Disance to Customer in 2 decimal places\n",
    "print('Average Disance to Customer ---->: ', round(df_exploded['distance_to_customer_km'].mean(), 2))\n",
    "\n",
    "# Popular Location\n",
    "print('Popular Location ---->: ', df_exploded['location'].mode()[0])\n",
    "\n",
    "# Types of cuisine\n",
    "print('Types of cuisine ---->: ', df_exploded['cuisine'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040323ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b98b1a3",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2716831d",
   "metadata": {},
   "source": [
    "### Step 1.4: Exploratory Data Analysis\n",
    "\n",
    "- Here we will be performing an exploratory data analysis on the data to get a better understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb7a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71a4baa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
