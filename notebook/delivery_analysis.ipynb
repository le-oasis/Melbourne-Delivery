{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f9faae4-1e3e-48ba-a3cd-d6970db40272",
   "metadata": {
    "id": "2f9faae4-1e3e-48ba-a3cd-d6970db40272"
   },
   "source": [
    "## Step 0: Initiate Libraries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c231464-4a4b-4a66-8321-f96302dc09e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T14:45:29.892708Z",
     "start_time": "2023-07-04T14:45:29.731937Z"
    },
    "id": "0c231464-4a4b-4a66-8321-f96302dc09e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "\n",
    "# Import Key Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Import Data Preprocessing Libraries\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# ast : Abstract Syntax Trees\n",
    "from ast import literal_eval\n",
    "\n",
    "# Import Geospatial Libraries\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from geopy.distance import geodesic\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import *\n",
    "import reverse_geocoder as rg \n",
    "\n",
    "# Datetime\n",
    "import datetime\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "# Data Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "import plotly.graph_objs as go\n",
    "from plotly.tools import FigureFactory as FF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34a3830a-cb7f-48ea-8e25-3c4aa759032e",
   "metadata": {
    "id": "34a3830a-cb7f-48ea-8e25-3c4aa759032e"
   },
   "source": [
    "## Step 1: Read Data\n",
    "\n",
    "- Here will we be reading the raw data as -  `dirty_data.csv` file into our jupyter notebook.\n",
    "- The variable name for the Food Delivery data would be called `dataset` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633453ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T14:45:29.903414Z",
     "start_time": "2023-07-04T14:45:29.893924Z"
    },
    "id": "633453ac",
    "tags": []
   },
   "outputs": [],
   "source": [
    "delivery_data = pd.read_csv('/Users/oasis/dataengineer/Melbourne-Delivery/data/dirty_data.csv')\n",
    "\n",
    "# Copy the data\n",
    "orders_df = delivery_data.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18a20a56-37c2-4dfb-8f66-28142e01931e",
   "metadata": {
    "id": "18a20a56-37c2-4dfb-8f66-28142e01931e"
   },
   "source": [
    "### Step 1.1: Data Discovery (Building Intuition)\n",
    "\n",
    "- This is a technique we use to get an initial feel for our data tables.\n",
    "- We read the data using pandas and perform method calls.\n",
    "- Standardize dataset columns in the correct format.\n",
    "- Explore Descriptive Statistics on Numerical Columns and more below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63e102aa",
   "metadata": {
    "id": "63e102aa"
   },
   "source": [
    "##### `df.info()`\n",
    "\n",
    "- It is an important and widely used method of Python.\n",
    "- This Method prints the information or summary of the dataframe.\n",
    "- It prints the various information of the Dataframe such as index type, dtype, columns, non-values, and memory usage. It gives a quick overview of the dataset.\n",
    "- Info Method to get the Non-Null Count & Dtype (data type) of the dataset,\n",
    "- Validate if a column and column type aligns with the format of the Business Requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c083d1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T14:45:29.955377Z",
     "start_time": "2023-07-04T14:45:29.922555Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c083d1a",
    "outputId": "2283d68b-902c-45d7-d0e1-f39f87c8390c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   order_id                 500 non-null    object \n",
      " 1   date                     500 non-null    object \n",
      " 2   time                     500 non-null    object \n",
      " 3   order_type               500 non-null    object \n",
      " 4   branch_code              500 non-null    object \n",
      " 5   order_items              500 non-null    object \n",
      " 6   order_price              500 non-null    float64\n",
      " 7   customer_lat             500 non-null    float64\n",
      " 8   customer_lon             500 non-null    float64\n",
      " 9   customerHasloyalty?      500 non-null    int64  \n",
      " 10  distance_to_customer_KM  500 non-null    float64\n",
      " 11  delivery_fee             500 non-null    float64\n",
      "dtypes: float64(5), int64(1), object(6)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "orders_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a0164e1",
   "metadata": {
    "id": "2a0164e1"
   },
   "source": [
    "Based on this information above:\n",
    "\n",
    "- The dataset has 500 rows and 12 columns.\n",
    "- The dataset has 0 null values.\n",
    "\n",
    "\n",
    "Data transformations and cleaning tasks that might be needed include:\n",
    "\n",
    "- Checking the data type of all columns to make sure they are in the appropriate format for analysis.\n",
    "- The `order_id`, `date`, `time`, `order_type`, `branch_code`, `order_items` columns datatypes need to be changed.\n",
    "- The `date` &  `time` need to be merged into a single column, renamed to `order_date` and converted to `datetime` dtype format for Parsing Dates.\n",
    "- Extracting the food items and their quantities from the `order_items` column into separate columns.\n",
    "- Checking the category column entries for case sensitivity (Checking if the values in the branch_code and order_type columns are consistent and correctly labeled.)\n",
    "- feature engineer the `order_date`  column, potentially separating them into year, month, day, and hour columns.\n",
    "- Removing any unnecessary or irrelevant columns.\n",
    "- Checking for outliers in numerical columns such as order_price, distance_to_customer_KM, and delivery_fee.\n",
    "- Checking if the customerHasloyalty? column only contains binary values (0 and 1).\n",
    "- Checking if the  `distance_to_customer_KM` column is consistent with the values in the `nodes.csv` file.\n",
    "- Checking if the `delivery_fee` column is consistent with the values in the `edges.csv`  file.\n",
    "- Checking if the `order_price` column is consistent with the values in the `order_items`  column.\n",
    "- Checking if the `order_price` column is consistent with the values in the  `delivery_fee` column.\n",
    "\n",
    "\n",
    "Remember, the goal of this process is to ensure that your dataset is clean, understandable, and ready for further Business Intelligence analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458dc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bFjYKlKRSj4-",
   "metadata": {
    "id": "bFjYKlKRSj4-"
   },
   "source": [
    "### Step 1.2: Data Preporcessing - Cleaning \n",
    "\n",
    "- Here we will be cleaning the data by converting the columns to the correct data types.\n",
    "- We will merge the date and time columns into one column called `order_date` and convert it to a datetime type.\n",
    "- We will also rename the `customerHasloyalty?` , `distance_to_customer_KM` columns to `customer_loyalty` , and  `distance_to_customer` respectively.\n",
    "- We will add an additional column called `updated at` which will be the date and time the data was updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eNo-KF7Sj1V",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T14:45:38.184964Z",
     "start_time": "2023-07-04T14:45:38.169814Z"
    },
    "id": "4eNo-KF7Sj1V",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   order_id                 500 non-null    int64         \n",
      " 1   order_date               500 non-null    datetime64[ns]\n",
      " 2   order_type               500 non-null    category      \n",
      " 3   branch_code              500 non-null    category      \n",
      " 4   order_items              500 non-null    object        \n",
      " 5   order_price              500 non-null    float64       \n",
      " 6   customer_loyalty         500 non-null    bool          \n",
      " 7   distance_to_customer_km  500 non-null    float64       \n",
      " 8   delivery_fee             500 non-null    float64       \n",
      " 9   location                 500 non-null    object        \n",
      " 10  updated_at               500 non-null    datetime64[ns]\n",
      "dtypes: bool(1), category(2), datetime64[ns](2), float64(3), int64(1), object(2)\n",
      "memory usage: 33.1+ KB\n"
     ]
    }
   ],
   "source": [
    "def reverseGeocode(coordinates): \n",
    "    result = rg.search(coordinates)\n",
    "    return (result)\n",
    "\n",
    "def cleaning_data_types(orders_df):\n",
    "    # Create a copy of the DataFrame to avoid modifying the original one\n",
    "    df_clean = orders_df.copy()\n",
    "\n",
    "    # Define helper function to clean date data\n",
    "    def clean_date(date_str):\n",
    "        date_str = date_str.strip()\n",
    "        date = parse(date_str, dayfirst=True)  # dayfirst=True to handle DD/MM/YYYY properly\n",
    "        return date.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Convert columns to appropriate data types\n",
    "    df_clean['order_id'] = df_clean['order_id'].str.extract('(\\d+)').astype(int)\n",
    "    df_clean['date'] = df_clean['date'].apply(clean_date).astype('datetime64[ns]')\n",
    "    df_clean['datetime'] = pd.to_datetime(df_clean['date'].astype(str) + ' ' + df_clean['time'])\n",
    "    df_clean[\"order_type\"] = df_clean[\"order_type\"].astype(\"category\")\n",
    "\n",
    "   \n",
    "    # Convert 'branch_code' to upper case to handle case-insensitive duplicates\n",
    "    df_clean[\"branch_code\"] = df_clean[\"branch_code\"].str.upper().astype(\"category\")\n",
    "\n",
    "\n",
    "    # Use exception handling for potential errors in the literal_eval() function\n",
    "    try:\n",
    "        df_clean[\"order_items\"] = df_clean[\"order_items\"].apply(literal_eval)\n",
    "    except (ValueError, SyntaxError):\n",
    "        pass\n",
    "\n",
    "    # Continue with the remaining conversions\n",
    "    df_clean[\"order_price\"] = df_clean[\"order_price\"].astype(float)\n",
    "    df_clean[\"customer_lat\"] = df_clean[\"customer_lat\"].astype(float)\n",
    "    df_clean[\"customer_lon\"] = df_clean[\"customer_lon\"].astype(float)\n",
    "    df_clean[\"customerHasloyalty?\"] = df_clean[\"customerHasloyalty?\"].astype(bool)\n",
    "    df_clean[\"distance_to_customer_KM\"] = df_clean[\"distance_to_customer_KM\"].astype(float)\n",
    "    df_clean[\"delivery_fee\"] = df_clean[\"delivery_fee\"].astype(float)\n",
    "\n",
    "\n",
    "    # make the order_price two decimal places\n",
    "    df_clean['order_price'] = df_clean['order_price'].round(2)\n",
    "\n",
    "    # make the delivery fee two decimal places\n",
    "    df_clean['delivery_fee'] = df_clean['delivery_fee'].round(2)\n",
    "\n",
    "\n",
    "    # transform long/lat into state\n",
    "    coordinates =list(zip(df_clean['customer_lat'],df_clean['customer_lon'])) # generates pair of (lat,long)\n",
    "    data = reverseGeocode(coordinates)\n",
    "\n",
    "\n",
    "    # Create a new column with the City name    \n",
    "    df_clean['name'] = [i['name'] for i in data]\n",
    "    df_clean['admin1'] = [i['admin1'] for i in data]\n",
    "    df_clean['admin2'] = [i['admin2'] for i in data]\n",
    "\n",
    "\n",
    "    df_clean.drop(['admin1', 'admin2'], axis=1, inplace=True)\n",
    "    df_clean.rename(columns={'name': 'location'}, inplace=True)\n",
    " \n",
    "\n",
    "    # Rename the customerHasloyalty? column to customerHasloyalty\n",
    "    df_clean.rename(columns={'customerHasloyalty?': 'customer_loyalty'}, inplace=True)\n",
    "\n",
    "    # Rename the distance_to_customer_KM column to distance_to_customer_km\n",
    "    df_clean.rename(columns={'distance_to_customer_KM': 'distance_to_customer_km'}, inplace=True)\n",
    "\n",
    "    # Drop the 'date' and 'time' columns\n",
    "    df_clean.drop(['date', 'time'], axis=1, inplace=True)\n",
    "\n",
    "    # Rename the 'datetime' column to 'order_date' and move it to the second position\n",
    "    df_clean.rename(columns={'datetime': 'order_date'}, inplace=True)\n",
    "    order_date = df_clean.pop('order_date')\n",
    "    df_clean.insert(1, 'order_date', order_date)\n",
    "\n",
    "    # Add the 'updated_at' column with the current datetime\n",
    "    df_clean['updated_at'] = datetime.datetime.today().replace(second=0, microsecond=0)\n",
    "\n",
    "    df_clean.drop(['customer_lat', 'customer_lon'], axis=1, inplace=True)\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "df_clean = cleaning_data_types(orders_df)\n",
    "df_clean.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f6f7de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>order_type</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>order_items</th>\n",
       "      <th>order_price</th>\n",
       "      <th>customer_loyalty</th>\n",
       "      <th>distance_to_customer_km</th>\n",
       "      <th>delivery_fee</th>\n",
       "      <th>location</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1406</td>\n",
       "      <td>2018-07-08 15:16:03</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Fries, 6), (Salad, 4)]</td>\n",
       "      <td>140.80</td>\n",
       "      <td>True</td>\n",
       "      <td>8.335</td>\n",
       "      <td>13.70</td>\n",
       "      <td>Docklands</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10125</td>\n",
       "      <td>2018-12-01 08:20:16</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Cereal, 8), (Pancake, 6)]</td>\n",
       "      <td>313.50</td>\n",
       "      <td>True</td>\n",
       "      <td>7.536</td>\n",
       "      <td>6.17</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4175</td>\n",
       "      <td>2018-06-07 14:05:04</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Steak, 3), (Salad, 1), (Chicken, 6), (Fries,...</td>\n",
       "      <td>714.00</td>\n",
       "      <td>False</td>\n",
       "      <td>9.860</td>\n",
       "      <td>15.09</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3691</td>\n",
       "      <td>2018-04-26 11:43:05</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Pancake, 9), (Eggs, 10), (Cereal, 2)]</td>\n",
       "      <td>480.25</td>\n",
       "      <td>False</td>\n",
       "      <td>8.614</td>\n",
       "      <td>13.68</td>\n",
       "      <td>Southbank</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4094</td>\n",
       "      <td>2018-04-10 11:12:40</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Eggs, 5), (Coffee, 3), (Pancake, 9), (Cereal...</td>\n",
       "      <td>497.75</td>\n",
       "      <td>False</td>\n",
       "      <td>8.802</td>\n",
       "      <td>13.76</td>\n",
       "      <td>Southbank</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10193</td>\n",
       "      <td>2018-10-15 17:27:53</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>TP</td>\n",
       "      <td>[(Fish&amp;Chips, 5), (Shrimp, 5), (Salmon, 2), (P...</td>\n",
       "      <td>664.50</td>\n",
       "      <td>False</td>\n",
       "      <td>9.081</td>\n",
       "      <td>13.39</td>\n",
       "      <td>Kamaishi</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>958</td>\n",
       "      <td>2018-05-25 12:43:56</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>BK</td>\n",
       "      <td>[(Salad, 2), (Steak, 7), (Chicken, 2)]</td>\n",
       "      <td>413.40</td>\n",
       "      <td>False</td>\n",
       "      <td>6.412</td>\n",
       "      <td>12.01</td>\n",
       "      <td>Collingwood</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3630</td>\n",
       "      <td>2018-09-30 16:57:27</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Shrimp, 8), (Fish&amp;Chips, 6), (Salmon, 4), (P...</td>\n",
       "      <td>998.50</td>\n",
       "      <td>False</td>\n",
       "      <td>7.759</td>\n",
       "      <td>16.25</td>\n",
       "      <td>Kamaishi</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5755</td>\n",
       "      <td>2018-07-03 10:01:41</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Cereal, 1), (Coffee, 7), (Pancake, 3)]</td>\n",
       "      <td>146.25</td>\n",
       "      <td>False</td>\n",
       "      <td>8.996</td>\n",
       "      <td>14.11</td>\n",
       "      <td>East Melbourne</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8573</td>\n",
       "      <td>2018-04-21 11:32:57</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Eggs, 7), (Cereal, 8), (Pancake, 3), (Coffee...</td>\n",
       "      <td>417.25</td>\n",
       "      <td>False</td>\n",
       "      <td>8.624</td>\n",
       "      <td>15.76</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6221</td>\n",
       "      <td>2018-09-03 10:11:49</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>[(Eggs, 6), (Cereal, 10)]</td>\n",
       "      <td>658.40</td>\n",
       "      <td>False</td>\n",
       "      <td>8.163</td>\n",
       "      <td>12.82</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id          order_date order_type branch_code   \n",
       "0       1406 2018-07-08 15:16:03      Lunch          NS  \\\n",
       "1      10125 2018-12-01 08:20:16  Breakfast          NS   \n",
       "2       4175 2018-06-07 14:05:04      Lunch          NS   \n",
       "3       3691 2018-04-26 11:43:05     Dinner          NS   \n",
       "4       4094 2018-04-10 11:12:40  Breakfast          NS   \n",
       "5      10193 2018-10-15 17:27:53     Dinner          TP   \n",
       "6        958 2018-05-25 12:43:56  Breakfast          BK   \n",
       "7       3630 2018-09-30 16:57:27     Dinner          NS   \n",
       "8       5755 2018-07-03 10:01:41  Breakfast          NS   \n",
       "9       8573 2018-04-21 11:32:57  Breakfast          NS   \n",
       "10      6221 2018-09-03 10:11:49  Breakfast          NS   \n",
       "\n",
       "                                          order_items  order_price   \n",
       "0                            [(Fries, 6), (Salad, 4)]       140.80  \\\n",
       "1                         [(Cereal, 8), (Pancake, 6)]       313.50   \n",
       "2   [(Steak, 3), (Salad, 1), (Chicken, 6), (Fries,...       714.00   \n",
       "3             [(Pancake, 9), (Eggs, 10), (Cereal, 2)]       480.25   \n",
       "4   [(Eggs, 5), (Coffee, 3), (Pancake, 9), (Cereal...       497.75   \n",
       "5   [(Fish&Chips, 5), (Shrimp, 5), (Salmon, 2), (P...       664.50   \n",
       "6              [(Salad, 2), (Steak, 7), (Chicken, 2)]       413.40   \n",
       "7   [(Shrimp, 8), (Fish&Chips, 6), (Salmon, 4), (P...       998.50   \n",
       "8            [(Cereal, 1), (Coffee, 7), (Pancake, 3)]       146.25   \n",
       "9   [(Eggs, 7), (Cereal, 8), (Pancake, 3), (Coffee...       417.25   \n",
       "10                          [(Eggs, 6), (Cereal, 10)]       658.40   \n",
       "\n",
       "    customer_loyalty  distance_to_customer_km  delivery_fee        location   \n",
       "0               True                    8.335         13.70       Docklands  \\\n",
       "1               True                    7.536          6.17       Melbourne   \n",
       "2              False                    9.860         15.09        Richmond   \n",
       "3              False                    8.614         13.68       Southbank   \n",
       "4              False                    8.802         13.76       Southbank   \n",
       "5              False                    9.081         13.39        Kamaishi   \n",
       "6              False                    6.412         12.01     Collingwood   \n",
       "7              False                    7.759         16.25        Kamaishi   \n",
       "8              False                    8.996         14.11  East Melbourne   \n",
       "9              False                    8.624         15.76       Melbourne   \n",
       "10             False                    8.163         12.82       Melbourne   \n",
       "\n",
       "            updated_at  \n",
       "0  2023-07-06 01:49:00  \n",
       "1  2023-07-06 01:49:00  \n",
       "2  2023-07-06 01:49:00  \n",
       "3  2023-07-06 01:49:00  \n",
       "4  2023-07-06 01:49:00  \n",
       "5  2023-07-06 01:49:00  \n",
       "6  2023-07-06 01:49:00  \n",
       "7  2023-07-06 01:49:00  \n",
       "8  2023-07-06 01:49:00  \n",
       "9  2023-07-06 01:49:00  \n",
       "10 2023-07-06 01:49:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f96806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('clean_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54fc64ae",
   "metadata": {},
   "source": [
    "### Step 1.3: Feature Engineering\n",
    "\n",
    "- Here we will be creating new columns from existing columns."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1327cc2d",
   "metadata": {},
   "source": [
    "#### Step 1.4: Feature Engineering ( `order_items` )\n",
    "\n",
    "- Here we will be extracting the food items and their quantities from the `order_items` column into separate columns.\n",
    "- `cuisine` which will be the type of cuisine the food item is.\n",
    "-  `order_items_count` which will be the total number of items ordered.\n",
    "-  `order_items_total` which will be the total price of the items ordered."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16a06931",
   "metadata": {},
   "source": [
    "#### Step 1.5: Feature Engineering ( `order_date` )\n",
    "\n",
    "- Here we will be creating new columns based on the existing columns in the dataset.\n",
    "- `order_time_of_day` which will be the hour of the day the order was made. (Morning, Afternoon, Evening, Night)\n",
    "- `order_day` which will be the day of the week the order was made. (Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday)\n",
    "-  `order_month` which will be the month of the year the order was made. (January, February, March, April, May, June, July, August, September, October, November, December)\n",
    "- `order_season` which will be the season the order was made. (Summer, Autumn, Winter, Spring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ff07fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>order_price</th>\n",
       "      <th>quantity_ordered</th>\n",
       "      <th>average_item_price</th>\n",
       "      <th>order_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>order_season</th>\n",
       "      <th>order_type</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>delivery_fee</th>\n",
       "      <th>location</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>customer_loyalty</th>\n",
       "      <th>distance_to_customer_km</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1406</td>\n",
       "      <td>2018-07-08 15:16:03</td>\n",
       "      <td>140.8</td>\n",
       "      <td>6</td>\n",
       "      <td>23.47</td>\n",
       "      <td>Jul</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>13.70</td>\n",
       "      <td>Docklands</td>\n",
       "      <td>Fries</td>\n",
       "      <td>True</td>\n",
       "      <td>8.335</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1406</td>\n",
       "      <td>2018-07-08 15:16:03</td>\n",
       "      <td>140.8</td>\n",
       "      <td>4</td>\n",
       "      <td>35.20</td>\n",
       "      <td>Jul</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>13.70</td>\n",
       "      <td>Docklands</td>\n",
       "      <td>Salad</td>\n",
       "      <td>True</td>\n",
       "      <td>8.335</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10125</td>\n",
       "      <td>2018-12-01 08:20:16</td>\n",
       "      <td>313.5</td>\n",
       "      <td>8</td>\n",
       "      <td>39.19</td>\n",
       "      <td>Dec</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>6.17</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Cereal</td>\n",
       "      <td>True</td>\n",
       "      <td>7.536</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10125</td>\n",
       "      <td>2018-12-01 08:20:16</td>\n",
       "      <td>313.5</td>\n",
       "      <td>6</td>\n",
       "      <td>52.25</td>\n",
       "      <td>Dec</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>NS</td>\n",
       "      <td>6.17</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Pancake</td>\n",
       "      <td>True</td>\n",
       "      <td>7.536</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4175</td>\n",
       "      <td>2018-06-07 14:05:04</td>\n",
       "      <td>714.0</td>\n",
       "      <td>3</td>\n",
       "      <td>238.00</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Thu</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>NS</td>\n",
       "      <td>15.09</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Steak</td>\n",
       "      <td>False</td>\n",
       "      <td>9.860</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id          order_date  order_price  quantity_ordered   \n",
       "0      1406 2018-07-08 15:16:03        140.8                 6  \\\n",
       "0      1406 2018-07-08 15:16:03        140.8                 4   \n",
       "1     10125 2018-12-01 08:20:16        313.5                 8   \n",
       "1     10125 2018-12-01 08:20:16        313.5                 6   \n",
       "2      4175 2018-06-07 14:05:04        714.0                 3   \n",
       "\n",
       "   average_item_price order_month day_of_week order_season order_type   \n",
       "0               23.47         Jul         Sun       Autumn      Lunch  \\\n",
       "0               35.20         Jul         Sun       Autumn      Lunch   \n",
       "1               39.19         Dec         Sat       Spring  Breakfast   \n",
       "1               52.25         Dec         Sat       Spring  Breakfast   \n",
       "2              238.00         Jun         Thu       Autumn      Lunch   \n",
       "\n",
       "  branch_code  delivery_fee   location  cuisine  customer_loyalty   \n",
       "0          NS         13.70  Docklands    Fries              True  \\\n",
       "0          NS         13.70  Docklands    Salad              True   \n",
       "1          NS          6.17  Melbourne   Cereal              True   \n",
       "1          NS          6.17  Melbourne  Pancake              True   \n",
       "2          NS         15.09   Richmond    Steak             False   \n",
       "\n",
       "   distance_to_customer_km          updated_at  \n",
       "0                    8.335 2023-07-06 01:49:00  \n",
       "0                    8.335 2023-07-06 01:49:00  \n",
       "1                    7.536 2023-07-06 01:49:00  \n",
       "1                    7.536 2023-07-06 01:49:00  \n",
       "2                    9.860 2023-07-06 01:49:00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_en(df_clean):\n",
    "    # Create a copy of the DataFrame to avoid modifying the original one\n",
    "    df = df_clean.copy()\n",
    "\n",
    "   # Explode the 'order_items' column\n",
    "    df_exploded = df.explode('order_items')\n",
    "\n",
    "    # Split the tuple into two new columns\n",
    "    df_exploded[['cuisine', 'quantity_ordered']] = pd.DataFrame(df_exploded['order_items'].tolist(), index=df_exploded.index)\n",
    "\n",
    "    # average_order_price = order_items_total / quantity_ordered\n",
    "    df_exploded['average_item_price'] = df_exploded['order_price'] / df_exploded['quantity_ordered']\n",
    "\n",
    "    # two decimal places\n",
    "    df_exploded['average_item_price'] = df_exploded['average_item_price'].round(2)\n",
    "\n",
    "    # Drop the 'order_items' column\n",
    "    df_exploded.drop('order_items', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    # Extract the year, month as Jan, Feb, Mar, etc. Add them as new columns\n",
    "    df_exploded['order_month'] = df_exploded['order_date'].dt.strftime('%b')\n",
    "    df_exploded['day_of_week'] = df_exploded['order_date'].dt.strftime('%a')\n",
    "\n",
    "    # new column for the season the order was made. (Spring, Summer, Autumn, Winter)\n",
    "    df_exploded['order_season'] = df_exploded['order_date'].dt.month.apply(lambda x: (x%12 + 3)//3)\n",
    "    \n",
    "    # change the season number to season name\n",
    "    df_exploded['order_season'] = df_exploded['order_season'].map({1:'Spring', 2:'Summer', 3:'Autumn', 4:'Winter'})\n",
    "\n",
    "    # reposition the columns \n",
    "    df_exploded = df_exploded[['order_id', 'order_date' , 'order_price', 'quantity_ordered' , 'average_item_price', 'order_month', 'day_of_week', 'order_season' , 'order_type', 'branch_code' , 'delivery_fee', 'location', 'cuisine' , 'customer_loyalty', 'distance_to_customer_km','updated_at']]\n",
    "\n",
    "    return df_exploded\n",
    "\n",
    "df_exploded = feature_en(df_clean)\n",
    "df_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2983b0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1596 entries, 0 to 499\n",
      "Data columns (total 16 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   order_id                 1596 non-null   int64         \n",
      " 1   order_date               1596 non-null   datetime64[ns]\n",
      " 2   order_price              1596 non-null   float64       \n",
      " 3   quantity_ordered         1596 non-null   int64         \n",
      " 4   average_item_price       1596 non-null   float64       \n",
      " 5   order_month              1596 non-null   object        \n",
      " 6   day_of_week              1596 non-null   object        \n",
      " 7   order_season             1596 non-null   object        \n",
      " 8   order_type               1596 non-null   category      \n",
      " 9   branch_code              1596 non-null   category      \n",
      " 10  delivery_fee             1596 non-null   float64       \n",
      " 11  location                 1596 non-null   object        \n",
      " 12  cuisine                  1596 non-null   object        \n",
      " 13  customer_loyalty         1596 non-null   bool          \n",
      " 14  distance_to_customer_km  1596 non-null   float64       \n",
      " 15  updated_at               1596 non-null   datetime64[ns]\n",
      "dtypes: bool(1), category(2), datetime64[ns](2), float64(4), int64(2), object(5)\n",
      "memory usage: 179.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_exploded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad4009a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eafb9790",
   "metadata": {},
   "source": [
    "### Step 2: Descriptive Statistics \n",
    "\n",
    "- Descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset's distribution, excluding NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ebbddea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>order_price</th>\n",
       "      <th>quantity_ordered</th>\n",
       "      <th>average_item_price</th>\n",
       "      <th>order_month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>order_season</th>\n",
       "      <th>order_type</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>delivery_fee</th>\n",
       "      <th>location</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>customer_loyalty</th>\n",
       "      <th>distance_to_customer_km</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1596.000000</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596.000000</td>\n",
       "      <td>1596.000000</td>\n",
       "      <td>1596.000000</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596.000000</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596.000000</td>\n",
       "      <td>1596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nov</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Shrimp</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169</td>\n",
       "      <td>259</td>\n",
       "      <td>447</td>\n",
       "      <td>578</td>\n",
       "      <td>560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>264</td>\n",
       "      <td>145</td>\n",
       "      <td>1416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5385.418546</td>\n",
       "      <td>2018-07-11 11:51:11.128445696</td>\n",
       "      <td>546.506234</td>\n",
       "      <td>5.461153</td>\n",
       "      <td>145.460702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.906479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.679623</td>\n",
       "      <td>2023-07-06 01:49:00.000000256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2018-01-03 09:51:32</td>\n",
       "      <td>46.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.120000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.077000</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2586.000000</td>\n",
       "      <td>2018-04-16 11:22:49</td>\n",
       "      <td>322.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>61.757500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.710000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.666000</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5441.500000</td>\n",
       "      <td>2018-07-05 14:05:04</td>\n",
       "      <td>496.800000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>100.380000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.040000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.760000</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8240.000000</td>\n",
       "      <td>2018-10-11 18:18:35</td>\n",
       "      <td>726.800000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>165.585000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.420000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.840250</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11102.000000</td>\n",
       "      <td>2018-12-31 20:00:00</td>\n",
       "      <td>1465.500000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1191.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.110000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.892000</td>\n",
       "      <td>2023-07-06 01:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3180.732665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278.316498</td>\n",
       "      <td>2.882287</td>\n",
       "      <td>145.022853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.512300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.628888</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            order_id                     order_date  order_price   \n",
       "count    1596.000000                           1596  1596.000000  \\\n",
       "unique           NaN                            NaN          NaN   \n",
       "top              NaN                            NaN          NaN   \n",
       "freq             NaN                            NaN          NaN   \n",
       "mean     5385.418546  2018-07-11 11:51:11.128445696   546.506234   \n",
       "min         5.000000            2018-01-03 09:51:32    46.400000   \n",
       "25%      2586.000000            2018-04-16 11:22:49   322.400000   \n",
       "50%      5441.500000            2018-07-05 14:05:04   496.800000   \n",
       "75%      8240.000000            2018-10-11 18:18:35   726.800000   \n",
       "max     11102.000000            2018-12-31 20:00:00  1465.500000   \n",
       "std      3180.732665                            NaN   278.316498   \n",
       "\n",
       "        quantity_ordered  average_item_price order_month day_of_week   \n",
       "count        1596.000000         1596.000000        1596        1596  \\\n",
       "unique               NaN                 NaN          12           7   \n",
       "top                  NaN                 NaN         Nov         Sat   \n",
       "freq                 NaN                 NaN         169         259   \n",
       "mean            5.461153          145.460702         NaN         NaN   \n",
       "min             1.000000           10.120000         NaN         NaN   \n",
       "25%             3.000000           61.757500         NaN         NaN   \n",
       "50%             5.000000          100.380000         NaN         NaN   \n",
       "75%             8.000000          165.585000         NaN         NaN   \n",
       "max            10.000000         1191.500000         NaN         NaN   \n",
       "std             2.882287          145.022853         NaN         NaN   \n",
       "\n",
       "       order_season order_type branch_code  delivery_fee   location cuisine   \n",
       "count          1596       1596        1596   1596.000000       1596    1596  \\\n",
       "unique            4          3           3           NaN         17      13   \n",
       "top          Winter     Dinner          NS           NaN  Melbourne  Shrimp   \n",
       "freq            447        578         560           NaN        264     145   \n",
       "mean            NaN        NaN         NaN     13.906479        NaN     NaN   \n",
       "min             NaN        NaN         NaN      4.210000        NaN     NaN   \n",
       "25%             NaN        NaN         NaN     12.710000        NaN     NaN   \n",
       "50%             NaN        NaN         NaN     14.040000        NaN     NaN   \n",
       "75%             NaN        NaN         NaN     15.420000        NaN     NaN   \n",
       "max             NaN        NaN         NaN     22.110000        NaN     NaN   \n",
       "std             NaN        NaN         NaN      2.512300        NaN     NaN   \n",
       "\n",
       "       customer_loyalty  distance_to_customer_km   \n",
       "count              1596              1596.000000  \\\n",
       "unique                2                      NaN   \n",
       "top               False                      NaN   \n",
       "freq               1416                      NaN   \n",
       "mean                NaN                 8.679623   \n",
       "min                 NaN                 4.077000   \n",
       "25%                 NaN                 7.666000   \n",
       "50%                 NaN                 8.760000   \n",
       "75%                 NaN                 9.840250   \n",
       "max                 NaN                12.892000   \n",
       "std                 NaN                 1.628888   \n",
       "\n",
       "                           updated_at  \n",
       "count                            1596  \n",
       "unique                            NaN  \n",
       "top                               NaN  \n",
       "freq                              NaN  \n",
       "mean    2023-07-06 01:49:00.000000256  \n",
       "min               2023-07-06 01:49:00  \n",
       "25%               2023-07-06 01:49:00  \n",
       "50%               2023-07-06 01:49:00  \n",
       "75%               2023-07-06 01:49:00  \n",
       "max               2023-07-06 01:49:00  \n",
       "std                               NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive Statistics\n",
    "df_exploded.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f6d5a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders Date Range ---->:  2018-01-03 09:51:32 to 2018-12-31 20:00:00\n",
      "Order Price Range ---->:  46.4 to 1465.5\n",
      "Average Order Price ---->:  546.51\n",
      "Popular Order Type ---->:  Dinner\n",
      "Popular Cuisine ---->:  Shrimp\n",
      "Popular Branch ---->:  NS\n",
      "Popular Day of the Week ---->:  Sat\n",
      "Popular Season ---->:  Winter\n",
      "Popular Month ---->:  Nov\n",
      "Popular Hour ---->:  18\n",
      "Delivery Fee Range ---->:  4.21 to 22.11\n",
      "Average Disance to Customer ---->:  8.68\n",
      "Popular Location ---->:  Melbourne\n",
      "Types of cuisine ---->:  ['Fries' 'Salad' 'Cereal' 'Pancake' 'Steak' 'Chicken' 'Burger' 'Eggs'\n",
      " 'Coffee' 'Fish&Chips' 'Shrimp' 'Salmon' 'Pasta']\n"
     ]
    }
   ],
   "source": [
    "# Base on the information from the describe() method:\n",
    "\n",
    "#  Orders Date Range \n",
    "print('Orders Date Range ---->: ', df_exploded['order_date'].min(), 'to', df_exploded['order_date'].max())\n",
    "\n",
    "# Order Price Range\n",
    "print('Order Price Range ---->: ', df_exploded['order_price'].min(), 'to', df_exploded['order_price'].max())\n",
    "\n",
    "# Average Order Price in 2 decimal places\n",
    "print('Average Order Price ---->: ', round(df_exploded['order_price'].mean(), 2))\n",
    "\n",
    "# Popular Order Type\n",
    "print('Popular Order Type ---->: ', df_exploded['order_type'].mode()[0])\n",
    "\n",
    "# Popular Cuisine\n",
    "print('Popular Cuisine ---->: ', df_exploded['cuisine'].mode()[0])\n",
    "\n",
    "# Popular Branch\n",
    "print('Popular Branch ---->: ', df_exploded['branch_code'].mode()[0])\n",
    "\n",
    "# Popular Day of the Week\n",
    "print('Popular Day of the Week ---->: ', df_exploded['day_of_week'].mode()[0])\n",
    "\n",
    "# Popular Season\n",
    "print('Popular Season ---->: ', df_exploded['order_season'].mode()[0])\n",
    "\n",
    "# Popular Month\n",
    "print('Popular Month ---->: ', df_exploded['order_month'].mode()[0])\n",
    "\n",
    "# Pupluar Hour\n",
    "print('Popular Hour ---->: ', df_exploded['order_date'].dt.hour.mode()[0])\n",
    "\n",
    "# Delivery Fee Range\n",
    "print('Delivery Fee Range ---->: ', df_exploded['delivery_fee'].min(), 'to', df_exploded['delivery_fee'].max())\n",
    "\n",
    "# Average Disance to Customer in 2 decimal places\n",
    "print('Average Disance to Customer ---->: ', round(df_exploded['distance_to_customer_km'].mean(), 2))\n",
    "\n",
    "# Popular Location\n",
    "print('Popular Location ---->: ', df_exploded['location'].mode()[0])\n",
    "\n",
    "# Types of cuisine\n",
    "print('Types of cuisine ---->: ', df_exploded['cuisine'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040323ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b98b1a3",
   "metadata": {},
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
